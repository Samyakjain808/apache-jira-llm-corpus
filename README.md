# Apache Jira â†’ JSONL Corpus Pipeline

A **production-grade, fault-tolerant data pipeline** that scrapes public **Apache Jira** projects and converts them into a **clean, LLM-ready JSONL corpus**.  
Built for performance, recoverability, and data quality â€” complete with **tests, CI, schema validation, checkpointing, and Docker support.**

---

## ðŸŒŸ Highlights

- âš™ï¸ **Resumable & Fault-Tolerant:** SQLite-based state checkpointing with safe recovery  
- ðŸ” **Smart Retries & Backoff:** Handles `429` / `5xx` gracefully via capped exponential backoff + jitter  
- ðŸ§± **Structured LLM Corpus:** Deterministic JSONL export validated via JSON Schema  
- ðŸ§ª **CI-Driven Quality:** Pytest + GitHub Actions (lint, test, validate)  
- ðŸ§° **Pre-commit & Code Quality:** Black â€¢ isort â€¢ Flake8  
- ðŸ³ **Docker-Ready:** Portable, reproducible, environment-agnostic  

---

## ðŸ§© Architecture & Design

```text
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚          Apache Jira Cloud API         â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚              Scraper Layer (scraper.py)              â”‚
       â”‚  - Handles pagination, rate limits, retries          â”‚
       â”‚  - Extracts issues, metadata, comments               â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚           Checkpointing & Persistence (db.py)        â”‚
       â”‚  - SQLite checkpoint with resumable offsets          â”‚
       â”‚  - Fault-tolerant recovery on restart                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚         Transformation & Cleaning (transform.py)     â”‚
       â”‚  - Normalize fields, remove HTML, sanitize text      â”‚
       â”‚  - Derive tasks: "bug_summary", "discussion_text"    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚        Validation & Export (validate.py)             â”‚
       â”‚  - JSON Schema enforcement                           â”‚
       â”‚  - Writes clean corpus to `data/final_corpus.jsonl`  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               LLM Corpus (Output)                    â”‚
       â”‚  JSONL {id, project, summary, description, comments} â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```
---
## ðŸ—‚ï¸ Directory Layout
```bash
apache-jira-llm-corpus/
â”œâ”€â”€ README.md                        # Full documentation (setup, architecture, usage, etc.)
â”œâ”€â”€ requirements.txt                  # All dependencies (httpx, tqdm, tenacity, pytest, etc.)
â”œâ”€â”€ .gitignore                        # Ignore venv, output, cache, etc.
â”œâ”€â”€ .flake8                           # Linting configuration (line length, exclusions)
â”œâ”€â”€ pyproject.toml                    # Black + isort configuration
â”œâ”€â”€ .pre-commit-config.yaml           # Hooks for black, isort, flake8
â”‚
â”œâ”€â”€ schema/
â”‚   â””â”€â”€ corpus.schema.json            # JSON Schema for corpus validation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run.py                        # CLI entrypoint: orchestrates scraping + transform
â”‚   â”œâ”€â”€ jira_client.py                # HTTP client (retries, pagination, 429/5xx handling)
â”‚   â”œâ”€â”€ scrape.py                     # Scraper logic (projects, issues, comments, resume)
â”‚   â”œâ”€â”€ transform.py                  # Normalize + build derived LLM tasks
â”‚   â”œâ”€â”€ validate_corpus.py            # JSONL schema validation tool
â”‚   â”œâ”€â”€ state.py                      # SQLite checkpoint: resume on failure
â”‚   â””â”€â”€ common.py                     # Shared helpers (logging, timestamps, utils)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_state.py                 # Unit test for SQLite state persistence
â”‚   â”œâ”€â”€ test_transform.py             # Tests normalization + derived tasks
â”‚   â””â”€â”€ conftest.py                   # (optional) shared pytest fixtures
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                    # Container build file
â”‚   â””â”€â”€ entrypoint.sh                 # Script that runs pipeline inside container
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                    # GitHub Actions: run pytest + flake8 + black check
â”‚
â”œâ”€â”€ output/                           # (auto-created)
â”‚   â”œâ”€â”€ corpus/
â”‚   â”‚   â””â”€â”€ apache_jira_corpus.jsonl  # Final LLM-ready JSONL corpus
â”‚   â”œâ”€â”€ logs/                         # Logs for each run
â”‚   â””â”€â”€ ckpt.sqlite                   # SQLite checkpoint (resume state)
â”‚
â””â”€â”€ venv/ or .venv/                   # Local virtual environment (excluded in .gitignore)
```
---

## Quickstart
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python -m src.run --projects HADOOP KAFKA SPARK --since 2018-01-01 --out output
# Output -> output/corpus/apache_jira_corpus.jsonl
```
---
## Validate output against schema
```bash
python -m src.validate_corpus --path output/corpus/apache_jira_corpus.jsonl --schema schema/corpus.schema.json
```

---

## ðŸ§ª Testing
```bash
pytest -q
```
### Includes:

- Unit tests for scraper, transform, and validation

- Integration tests using mock API responses

- JSON schema validation tests on sample data

---

## Docker
```bash
docker build -t apache-jira-corpus -f docker/Dockerfile .
docker run --rm -v $PWD/output:/app/output apache-jira-corpus
```

---
## ðŸ”„ Continuous Integration (CI)
GitHub Actions workflow (.github/workflows/ci.yml) executes:

âœ… Lint: flake8

âœ… Formatting Checks: black --check, isort --check-only

âœ… Tests: pytest

âœ… Schema Validation: JSONL compliance check

âœ… Docker Build Verification

---

## âš¡ Edge Cases & Reliability
| Category                   | Strategy                               |
| -------------------------- | -------------------------------------- |
| **Rate Limits (HTTP 429)** | Exponential backoff + jitter           |
| **Server Errors (5xx)**    | Retries with capped delay              |
| **Malformed Data**         | Skip safely with logging               |
| **Network Failure**        | Resume from SQLite checkpoint          |
| **Pagination**             | Cursor-based incremental fetch         |
| **Duplicates**             | Hash-based deduplication               |
| **Validation**             | JSON Schema enforcement before export  |
| **Large Outputs**          | Streaming JSONL writer to bound memory |

---

## ðŸ§  Optimization Highlights
- Asynchronous I/O (aiohttp) for concurrent requests

- Batch writes to minimize I/O overhead

- Cached regex + sanitizer utilities

- Deterministic transforms for reproducibility

- Structured logs with timings and row counts

---

## âœ… Assignment Requirement Mapping
| Requirement                             | Implementation                             |
| --------------------------------------- | ------------------------------------------ |
| Scrape 3 Apache Jira projects           | `scraper.py --projects`                    |
| Handle pagination, rate limits, retries | `scraper.py` with exponential backoff      |
| Resume from checkpoint                  | `db.py` SQLite resume logic                |
| Transform raw â†’ JSONL corpus            | `transform.py`                             |
| Validate structured data                | `validate.py` + `schema/issue_schema.json` |
| Unit & integration tests                | `pytest` in `/tests`                       |
| CI pipeline                             | `.github/workflows/ci.yml`                 |
| Docker support                          | `docker/Dockerfile`                        |
| Output clean corpus                     | `output/final_corpus.jsonl`                |
